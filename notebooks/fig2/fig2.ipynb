{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Global visualisation configuration ──────────────────────────────────────\n",
    "\n",
    "# 1.  General Matplotlib defaults\n",
    "# ── Global visualisation configuration ──────────────────────────────────────\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "mpl.rcParams.update({\n",
    "    # ── Canvas size & resolution ───────────────────────────────────────────\n",
    "    # Default figure size: 12×8 inches  →  4800×3200 px when exported at 400 dpi\n",
    "    \"figure.figsize\": (12, 8),\n",
    "    \"figure.dpi\": 200,       # crisp in-notebook / retina preview\n",
    "    \"savefig.dpi\": 400,      # print-quality PNG/PDF\n",
    "\n",
    "    # ── Fonts ──────────────────────────────────────────────────────────────\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Roboto\", \"DejaVu Sans\", \"Arial\"],\n",
    "    \"axes.titlesize\": 24,\n",
    "    # \"axes.titleweight\": \"bold\",\n",
    "    \"axes.labelsize\": 24,\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    \"legend.fontsize\": 20,\n",
    "\n",
    "    # ── Axis & spine aesthetics ────────────────────────────────────────────\n",
    "    \"axes.spines.top\": False,\n",
    "    \"axes.spines.right\": False,\n",
    "    \"axes.spines.left\": True,\n",
    "    \"axes.spines.bottom\": True,\n",
    "    \"axes.linewidth\": 1,\n",
    "    \"axes.grid\": True,\n",
    "    \"grid.color\": \"#E6E6E6\",\n",
    "    \"grid.linewidth\": 0.4,\n",
    "    \"grid.alpha\": 0.8,\n",
    "\n",
    "    # ── Colour cycle (colour-blind-safe) ───────────────────────────────────\n",
    "    \"axes.prop_cycle\": mpl.cycler(color=sns.color_palette(\"Set2\")),\n",
    "\n",
    "    # ── Figure background ─────────────────────────────────────────────────\n",
    "    \"figure.facecolor\": \"white\",\n",
    "})\n",
    "\n",
    "# Seaborn theme inherits the rcParams above\n",
    "sns.set_theme(context=\"talk\", style=\"whitegrid\", palette=\"Set2\")\n",
    "\n",
    "\n",
    "# 2.  Seaborn theme (inherits Matplotlib rcParams)\n",
    "sns.set_theme(\n",
    "    context=\"talk\",           # slightly larger fonts for presentations / papers\n",
    "    style=\"whitegrid\",        # grid only on y-axis (good for histograms)\n",
    "    palette=\"Set2\",           # matches the rcParams colour cycle\n",
    ")\n",
    "\n",
    "# 3.  Helper function for consistent figure export\n",
    "def savefig_nice(fig, filename, *, tight=True, dpi=300, **savefig_kwargs):\n",
    "    \"\"\"Save figure with tight layout and correct DPI.\"\"\"\n",
    "    if tight:\n",
    "        fig.tight_layout()\n",
    "    fig.savefig(filename, dpi=dpi, bbox_inches=\"tight\", transparent = True, **savefig_kwargs)\n",
    "\n",
    "# 4.  Colour constants for this project (optional convenience)\n",
    "COL_RAW      = sns.color_palette(\"Set2\")[0]  # e.g. unweighted sample\n",
    "COL_WEIGHTED = sns.color_palette(\"Set2\")[1]  # weighted sample\n",
    "COL_REF      = \"0.35\"                        # census reference (neutral grey)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATLAS = \"schaefer2018tian2020_400_7\"\n",
    "region_col = \"index\"\n",
    "# Load important files\n",
    "DATA_DIR = Path(\"/home/galkepler/Projects/neuroaging/data\")\n",
    "\n",
    "# Output directory for figures\n",
    "OUTPUT_DIR = Path(\"/home/galkepler/Projects/neuroaging/figures/fig2\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load the data\n",
    "parcels = pd.read_csv(DATA_DIR / \"external\" /\"atlases\" / ATLAS / \"parcels.csv\", index_col = 0)\n",
    "nifti = DATA_DIR / \"external\" / \"atlases\" / ATLAS / \"atlas.nii.gz\"\n",
    "nifti_matlab = DATA_DIR / \"external\" / \"atlases\" / ATLAS / \"atlas_matlab.nii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_115033/2323632597.py:3: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(DATA_DIR / \"processed\" / f\"{metric}.csv\",index_col=0).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "metric = \"gm_vol\"\n",
    "distribution_metric = \"nanmedian\"\n",
    "data = pd.read_csv(DATA_DIR / \"processed\" / f\"{metric}.csv\",index_col=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_col = \"volume\" if metric == \"gm_vol\" else distribution_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if metric == \"gm_vol\":\n",
    "    data_global = data.drop_duplicates(subset=[\"subject_code\"], keep=\"first\")\n",
    "else:\n",
    "    data_global = data.groupby(\"subject_code\").agg({distribution_metric: \"mean\",\"sex\":\"first\",\"age_at_scan\":\"first\"}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "israel_population = pd.read_csv(DATA_DIR / \"processed\" / \"israel_population.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_weights_by_population(\n",
    "    data: pd.DataFrame,\n",
    "    population_df: pd.DataFrame,\n",
    "    *,\n",
    "    age_col: str = \"age_at_scan\",\n",
    "    range_start: str = \"range_start\",\n",
    "    range_end: str = \"range_end\",\n",
    "    total: str = \"total\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Post-stratification weights so the age distribution of *data*\n",
    "    matches an external reference.\n",
    "\n",
    "    - Accepts integer or float ages.\n",
    "    - Handles boundary ages (include_lowest=True).\n",
    "    - Leaves bins with zero sample untouched (weight=0 → later dropped).\n",
    "    - Returns weights whose mean == 1 across *non-zero* weights.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Make sure population bins are well-formed\n",
    "    pop = (\n",
    "        population_df[[range_start, range_end, total]]\n",
    "        .sort_values(range_start)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    if (pop[range_end] <= pop[range_start]).any():\n",
    "        raise ValueError(\"Each range_end must exceed range_start.\")\n",
    "    if (pop[range_start].iloc[1:].values < pop[range_end].iloc[:-1].values).any():\n",
    "        raise ValueError(\"Age bins overlap or are not strictly increasing.\")\n",
    "\n",
    "    # 2. Bin edges for pd.cut  →  [..., last_end]  (right-inclusive)\n",
    "    bin_edges = pop[range_start].tolist() + [pop[range_end].iloc[-1]]\n",
    "\n",
    "    # Population proportions (works for % or counts)\n",
    "    pop_prop = pop[total] / pop[total].sum()\n",
    "\n",
    "    # 3. Assign each participant to a bin\n",
    "    sample_bins = pd.cut(\n",
    "        data[age_col],\n",
    "        bins=bin_edges,\n",
    "        right=True,            # include right edge\n",
    "        include_lowest=True,   # include first left edge\n",
    "        labels=pop.index,      # integer labels 0..n-1\n",
    "    )\n",
    "\n",
    "    # 4. Sample distribution\n",
    "    sample_counts = sample_bins.value_counts(sort=False)\n",
    "    sample_prop = sample_counts / sample_counts.sum()\n",
    "\n",
    "    # 5. Weight lookup  (population / sample)  — careful with zeros\n",
    "    weight_lookup = pop_prop / sample_prop.replace(0, np.nan)\n",
    "\n",
    "    # 6. Map to rows; bins with zero sample → NaN weight → drop later\n",
    "    w = sample_bins.map(weight_lookup).to_numpy()\n",
    "\n",
    "    # Assign *zero* weight (instead of 1) to rows that were NaN\n",
    "    w = np.where(np.isnan(w), 0.0, w)\n",
    "\n",
    "    # 7. Rescale so mean(weight > 0) == 1\n",
    "    positive = w > 0\n",
    "    w[positive] = w[positive] / w[positive].mean()\n",
    "\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def compute_poststrat_weights(\n",
    "    sample_df: pd.DataFrame,\n",
    "    pop_df: pd.DataFrame,\n",
    "    *,\n",
    "    age_col: str = \"age_at_scan\",\n",
    "    start_col: str = \"range_start\",\n",
    "    end_col: str = \"range_end\",\n",
    "    pop_total_col: str = \"total\",\n",
    "    cap: float | None = None,\n",
    "    return_bin_table: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Post-stratification weights so that the age distribution of *sample_df*\n",
    "    matches an external population distribution supplied in *pop_df*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sample_df : DataFrame with an ``age_col`` column (years; int or float).\n",
    "    pop_df    : DataFrame with columns\n",
    "                    [start_col, end_col, pop_total_col].\n",
    "                * Values in ``pop_total_col`` can be counts **or** percentages\n",
    "                  (they are internally re-scaled to proportions).\n",
    "                * The row order doesn’t matter; they will be sorted.\n",
    "    cap       : Optional float.  If provided, weights are truncated at  \n",
    "                ``cap × mean(weight)`` and then re-scaled so mean(weight)=1.\n",
    "    return_bin_table : If True, also return a DataFrame summarising\n",
    "                       n_sample, n_pop, and weight_factor for every bin.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    weights   : 1-D numpy array aligned with ``sample_df.index``.\n",
    "    bin_table : (optional) tidy per-bin summary (see above).\n",
    "    \"\"\"\n",
    "\n",
    "    # 1 ── tidy & validate the population table --------------------------------\n",
    "    pop = (\n",
    "        pop_df[[start_col, end_col, pop_total_col]]\n",
    "        .dropna()\n",
    "        .astype({start_col: int, end_col: int, pop_total_col: float})\n",
    "        .sort_values(start_col)         # your CSV is descending; fix that\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    if (pop[end_col] <= pop[start_col]).any():\n",
    "        raise ValueError(\"Each range_end must exceed range_start.\")\n",
    "\n",
    "    if (pop[start_col].iloc[1:].values < pop[end_col].iloc[:-1].values).any():\n",
    "        overlap = pop.iloc[\n",
    "            np.where(\n",
    "                pop[start_col].iloc[1:].values < pop[end_col].iloc[:-1].values\n",
    "            )[0] + 1\n",
    "        ][[start_col, end_col]]\n",
    "        raise ValueError(\n",
    "            \"Age bins overlap (rows shown below) — \"\n",
    "            \"merge / correct them before weighting:\\n\"\n",
    "            f\"{overlap}\"\n",
    "        )\n",
    "\n",
    "    # 2 ── build right-inclusive bin edges  (···| s_i  …  e_i | s_{i+1} …) ----\n",
    "    edges = pop[start_col].tolist() + [pop[end_col].iloc[-1]]\n",
    "\n",
    "    # 3 ── assign every participant to a bin -----------------------------------\n",
    "    s_bins = pd.cut(\n",
    "        sample_df[age_col],\n",
    "        bins=edges,\n",
    "        right=True,\n",
    "        include_lowest=True,\n",
    "        labels=pop.index,       # categorical labels 0,1,…\n",
    "    )\n",
    "\n",
    "    # 4 ── compute *sample* and *population* proportions per bin --------------\n",
    "    n_sample = s_bins.value_counts(sort=False).sort_index()\n",
    "    prop_sample = n_sample / n_sample.sum()\n",
    "\n",
    "    prop_pop = pop[pop_total_col] / pop[pop_total_col].sum()\n",
    "\n",
    "    # 5 ── weight factor = pop_prop / sample_prop ------------------------------\n",
    "    weight_factor = prop_pop / prop_sample.replace(0, np.nan)   # avoid /0 → NaN\n",
    "\n",
    "    # 6 ── map factor back to each row ----------------------------------------\n",
    "    w = s_bins.map(weight_factor).astype(float).to_numpy()\n",
    "    w = np.where(np.isnan(w), 0.0, w)      # rows that fell outside bins → 0\n",
    "\n",
    "    # 7 ── optional weight truncation (winsorisation) --------------------------\n",
    "    if cap is not None and cap > 0:\n",
    "        mean_pos = w[w > 0].mean()\n",
    "        w = np.clip(w, 0, cap * mean_pos)\n",
    "\n",
    "    # 8 ── re-scale so mean(weight > 0) == 1 -----------------------------------\n",
    "    positive = w > 0\n",
    "    w[positive] = w[positive] / w[positive].mean()\n",
    "\n",
    "    # 9 ── return --------------------------------------------------------------\n",
    "    if return_bin_table:\n",
    "        bin_tbl = pd.DataFrame(\n",
    "            {\n",
    "                \"n_sample\": n_sample,\n",
    "                \"n_pop\": prop_pop * n_sample.sum(),   # rescaled to sample size\n",
    "                \"prop_sample\": prop_sample,\n",
    "                \"prop_pop\": prop_pop,\n",
    "                \"weight_factor\": weight_factor,\n",
    "            }\n",
    "        )\n",
    "        return w, bin_tbl\n",
    "\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign weights\n",
    "data[\"weight\"],_ = compute_poststrat_weights(\n",
    "    data,\n",
    "    israel_population,\n",
    "    age_col=\"age_at_scan\",\n",
    "    cap=None,  # try None first; if still spiky, use 4 or 5\n",
    "    return_bin_table=True,\n",
    ")\n",
    "\n",
    "# change sex into numeric\n",
    "data[\"sex\"] = data[\"sex\"].map({\"M\": 0, \"F\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols, wls\n",
    "\n",
    "def regional_models(region_data:pd.DataFrame, metric_col:str, model:str, covariates:list):\n",
    "    \"\"\"\n",
    "    Fit a linear model to the data for each region.\n",
    "    \"\"\"\n",
    "    # Fit the model\n",
    "    if model == \"ols\":\n",
    "        model = ols(f\"{metric_col} ~ {' + '.join(covariates)}\", data=region_data)\n",
    "    elif model == \"wls\":\n",
    "        model = wls(f\"{metric_col} ~ {' + '.join(covariates)}\", data=region_data, weights=region_data[\"weight\"])\n",
    "    else:\n",
    "        raise ValueError(\"Model must be either 'ols' or 'wls'.\")\n",
    "\n",
    "    # Fit the model\n",
    "    results = model.fit()\n",
    "\n",
    "    # Return the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting models: 100%|██████████| 454/454 [00:08<00:00, 55.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Set up dataframes to store results\n",
    "lin_unw, lin_w, quad_unw, quad_w = parcels.copy(), parcels.copy(), parcels.copy(), parcels.copy()\n",
    "\n",
    "covariates = [\"sex\"]\n",
    "if metric == \"gm_vol\":\n",
    "    covariates += [\"tiv\"]\n",
    "\n",
    "for i, row in tqdm(parcels.iterrows(), total=parcels.shape[0], desc=\"Fitting models\"):\n",
    "    region_data = data[data[region_col] == row[region_col]].copy()\n",
    "    region_data.rename(columns={metric_col: \"value\"}, inplace=True)\n",
    "    for results_df, model, is_quadratic in zip(\n",
    "        [lin_unw, lin_w, quad_unw, quad_w],\n",
    "        [\"ols\", \"wls\", \"ols\", \"wls\"],\n",
    "        [False, False, True, True],\n",
    "    ):\n",
    "        # Fit the model\n",
    "        if is_quadratic:\n",
    "            region_data[\"age_squared\"] = region_data[\"age_at_scan\"] ** 2\n",
    "            results = regional_models(region_data, \"value\", model, covariates + [\"age_squared\"])\n",
    "        else:\n",
    "            results = regional_models(region_data, \"value\", model, covariates)\n",
    "\n",
    "        # Store the results\n",
    "        results_df.loc[i, \"model\"] = results\n",
    "        results_df.loc[i, \"pvalue\"] = results.f_pvalue\n",
    "        results_df.loc[i, \"r2\"] = results.rsquared\n",
    "        results_df.loc[i, \"r2_adj\"] = results.rsquared_adj\n",
    "        results_df.loc[i, \"n\"] = len(region_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting models: 100%|██████████| 454/454 [00:00<00:00, 1531.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "unw_compare = parcels.copy()\n",
    "w_compare = parcels.copy()\n",
    "\n",
    "# do f test to compare between quadratic and linear models\n",
    "for i, row in tqdm(parcels.iterrows(), total=parcels.shape[0], desc=\"Fitting models\"):\n",
    "    for results_lin, results_quad, results_df in zip(\n",
    "        [lin_unw, lin_w],\n",
    "        [quad_unw, quad_w],\n",
    "        [unw_compare, w_compare],\n",
    "    ):\n",
    "        # collect models\n",
    "        model1 = results_lin.loc[i, \"model\"]\n",
    "        model2 = results_quad.loc[i, \"model\"]\n",
    "        f, p, _ = model2.compare_f_test(model1)\n",
    "        results_df.loc[i, \"f\"] = f\n",
    "        results_df.loc[i, \"pvalue\"] = p\n",
    "        results_df.loc[i, \"n\"] = model1.nobs\n",
    "        # do f test to compare between quadratic and linear models\n",
    "    # model1 = lin_unw.loc[i, \"model\"]\n",
    "    # model2 = quad_unw.loc[i, \"model\"]\n",
    "    # f, p, _ = model2.compare_f_test(model1)\n",
    "    # unw_compare.loc[i, \"f\"] = f\n",
    "    # unw_compare.loc[i, \"pvalue\"] = p\n",
    "    # unw_compare.loc[i, \"n\"] = model1.nobs\n",
    "    # weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct everything for multiple comparisons\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "for results_df, save_name in zip([lin_unw, lin_w, quad_unw, quad_w, unw_compare, w_compare], [\"lin_unw\", \"lin_w\", \"quad_unw\", \"quad_w\", \"unw_compare\", \"w_compare\"]):\n",
    "    results_df[\"p_corrected\"] = multipletests(results_df[\"pvalue\"], method=\"fdr_bh\")[1]\n",
    "    results_df.to_csv(OUTPUT_DIR / f\"{save_name}_{metric}.csv\", index=False)\n",
    "\n",
    "# lin_unw[\"p_corrected\"] = multipletests(lin_unw[\"pvalue\"], method=\"fdr_bh\")[1]\n",
    "# lin_unw.to_csv(OUTPUT_DIR / f\"lin_unw_{metric}.csv\", index=False)\n",
    "\n",
    "# lin_w[\"p_corrected\"] = multipletests(lin_w[\"pvalue\"], method=\"fdr_bh\")[1]\n",
    "# lin_w.to_csv(OUTPUT_DIR / f\"lin_w_{metric}.csv\", index=False)\n",
    "\n",
    "# quad_unw[\"p_corrected\"] = multipletests(quad_unw[\"pvalue\"], method=\"fdr_bh\")[1]\n",
    "# quad_unw.to_csv(OUTPUT_DIR / f\"quad_unw_{metric}.csv\", index=False)\n",
    "\n",
    "# quad_w[\"p_corrected\"] = multipletests(quad_w[\"pvalue\"], method=\"fdr_bh\")[1]\n",
    "# unw_compare[\"p_corrected\"] = multipletests(unw_compare[\"pvalue\"], method=\"fdr_bh\")[1]\n",
    "# w_compare[\"p_corrected\"] = multipletests(w_compare[\"pvalue\"], method=\"fdr_bh\")[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nb\n",
    "from nilearn import surface, datasets\n",
    "from surfplot import Plot\n",
    "from matplotlib.colors import TwoSlopeNorm  # nice diverging colours\n",
    "\n",
    "atlas_img = nib.load(nifti)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 2.  FETCH A STANDARD SURFACE  (fsaverage5 = 10k vertices per hemi)\n",
    "# ---------------------------------------------------------------------\n",
    "fsavg = datasets.fetch_surf_fsaverage(\"fsaverage5\")  # ~5 MB download\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# 3.  SAMPLE ATLAS VOXELS → SURFACE  (nearest-neighbour so labels stay int)\n",
    "# ---------------------------------------------------------------------\n",
    "labels_lh = surface.vol_to_surf(atlas_img, fsavg[\"pial_left\"], interpolation=\"nearest\").astype(int)\n",
    "labels_rh = surface.vol_to_surf(atlas_img, fsavg[\"pial_right\"], interpolation=\"nearest\").astype(\n",
    "    int\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 4.  MAP REGION IDs → METRIC VALUES\n",
    "#     vertices with label 0 (background) → NaN so they render transparent\n",
    "# ---------------------------------------------------------------------\n",
    "p_threshold = 0.05\n",
    "\n",
    "value_map = {}\n",
    "\n",
    "vis_df = lin_unw\n",
    "for i, row in vis_df.iterrows():\n",
    "    value_map[row[region_col]] = row[\"r2_adj\"] if row[\"p_corrected\"] < p_threshold else np.nan\n",
    "\n",
    "vec = np.vectorize(lambda x: value_map.get(x, np.nan))\n",
    "data_lh = vec(labels_lh)\n",
    "data_rh = vec(labels_rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------\n",
    "# 5.  BUILD THE PLOT\n",
    "# ---------------------------------------------------------------------\n",
    "p = Plot(\n",
    "    fsavg[\"infl_left\"],\n",
    "    fsavg[\"infl_right\"],  # inflated surfaces\n",
    "    # views=\"latmed\",  # L-lat, L-med, R-lat, R-med\n",
    "    size=(1800, 800),  # px; change as needed\n",
    ")\n",
    "\n",
    "# ---- main data layer -------------------------------------------------\n",
    "# If your metric is centred on 0 (e.g., t-values) use TwoSlopeNorm for symmetry\n",
    "# norm = TwoSlopeNorm(\n",
    "#     vmin=np.nanmin([data_lh, data_rh]), ,vmax=np.nanmax([data_lh, data_rh])\n",
    "# )\n",
    "\n",
    "p.add_layer(\n",
    "    {\"left\": data_lh, \"right\": data_rh},\n",
    "    cmap=\"coolwarm\",\n",
    "    # color_range=\n",
    "    cbar_label=\"My metric\",\n",
    ")\n",
    "\n",
    "# ---- outline layer ---------------------------------------------------\n",
    "# Re-use the label arrays; surfplot draws borders when as_outline=True\n",
    "p.add_layer({\"left\": labels_lh, \"right\": labels_rh}, cmap=\"gray\", as_outline=True, cbar=False)\n",
    "\n",
    "fig = p.build(cbar_kws=dict(location=\"bottom\", decimals=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
